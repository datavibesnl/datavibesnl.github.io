"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[9386],{4613:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var t=n(4848),r=n(8453);const i={},a="4.6 Multihop Architecture (Hands On)",l={id:"Databricks Certified Data Engineer Associate - Preparation/Incremental Data Processing/4.6 Multihop Architecture Hands On",title:"4.6 Multihop Architecture (Hands On)",description:"Introduction",source:"@site/docs/Databricks Certified Data Engineer Associate - Preparation/4. Incremental Data Processing/4.6 Multihop Architecture Hands On.md",sourceDirName:"Databricks Certified Data Engineer Associate - Preparation/4. Incremental Data Processing",slug:"/Databricks Certified Data Engineer Associate - Preparation/Incremental Data Processing/4.6 Multihop Architecture Hands On",permalink:"/docs/Databricks Certified Data Engineer Associate - Preparation/Incremental Data Processing/4.6 Multihop Architecture Hands On",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"4.5 Multi-hop Architecture",permalink:"/docs/Databricks Certified Data Engineer Associate - Preparation/Incremental Data Processing/4.5 Multihop Architecture"},next:{title:"5.1 Delta Live Tables (Hands On)",permalink:"/docs/Databricks Certified Data Engineer Associate - Preparation/Production Pipelines/5.1 Delta Live Tables Hands On"}},o={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Dataset setup",id:"dataset-setup",level:2},{value:"Explore source directory",id:"explore-source-directory",level:2},{value:"How to implement the bronze layer",id:"how-to-implement-the-bronze-layer",level:2},{value:"How to implement the silver layer",id:"how-to-implement-the-silver-layer",level:2},{value:"Create a new temporary view from JSON files",id:"create-a-new-temporary-view-from-json-files",level:3},{value:"Create a streaming temporary view from an existing table",id:"create-a-streaming-temporary-view-from-an-existing-table",level:3},{value:"Combine orders with customers data",id:"combine-orders-with-customers-data",level:3},{value:"Parse Unix timestamp into human-readable format",id:"parse-unix-timestamp-into-human-readable-format",level:3},{value:"Exclude orders without items",id:"exclude-orders-without-items",level:3},{value:"Create a writeStream to persist data into a silver table",id:"create-a-writestream-to-persist-data-into-a-silver-table",level:3},{value:"How to implement the gold layer",id:"how-to-implement-the-gold-layer",level:2},{value:"How to aggregate data from a streaming data source",id:"how-to-aggregate-data-from-a-streaming-data-source",level:3},{value:"How to persist aggregated data into the gold table",id:"how-to-persist-aggregated-data-into-the-gold-table",level:3},{value:"Cleanup",id:"cleanup",level:2}];function d(e){const s={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",input:"input",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.h1,{id:"46-multihop-architecture-hands-on",children:"4.6 Multihop Architecture (Hands On)"}),"\n",(0,t.jsx)(s.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","In this notebook, we will create a Delta Lake multi-hop pipeline",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We will continue using our bookstore dataset, with its 3 tables: ",(0,t.jsx)("br",{})]}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["Customers;",(0,t.jsx)("br",{})]}),"\n",(0,t.jsxs)(s.li,{children:["Orders;",(0,t.jsx)("br",{})]}),"\n",(0,t.jsx)(s.li,{children:"Books"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"dataset-setup",children:"Dataset setup"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us start by running the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"Copy-Datasets"})})," script"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sh",children:"%run ../Includes/Copy-Datasts\n"})})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"explore-source-directory",children:"Explore source directory"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Before starting, let us first check our source directory"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'files = dbutils.fs.ls(\r\n    f"{dataset_bookstore}/orders-raw"\r\n)\r\ndisplay(files)\n'})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Currently we have 3 ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:".parquet"})})," files in our source directory",(0,t.jsx)("br",{})]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"how-to-implement-the-bronze-layer",children:"How to implement the bronze layer"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We start usually by creating an Auto Loader against our source directory",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Here, we are configuring a ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"readStream"})})," on our ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"parquet"})})," source using Auto Loader with schema inference"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",metastring:"{7-8}",children:'spark.readStream.format(\r\n    "cloudFiles"\r\n).option(\r\n    "cloudFiles.format",\r\n    "parquet"\r\n).option(\r\n    "cloudFiles.schemaLocation",\r\n    "dbfs:/mnt/demo/checkpoints/orders_raw"\r\n).load(\r\n    f"{dataset_bookstore}/orders-raw"\r\n).createOrReplaceTempView(\r\n    "orders_raw_temp"\r\n)\n'})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We register a streaming temporary view to do data transformation in Spark SQL",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Our temporary view is named ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"orders_raw_temp"})})]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",metastring:"{11-13}",children:'spark.readStream.format(\r\n    "cloudFiles"\r\n).option(\r\n    "cloudFiles.format",\r\n    "parquet"\r\n).option(\r\n    "cloudFiles.schemaLocation",\r\n    "dbfs:/mnt/demo/checkpoints/orders_raw"\r\n).load(\r\n    f"{dataset_bookstore}/orders-raw"\r\n).createOrReplaceTempView(\r\n    "orders_raw_temp"\r\n)\n'})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Our stream has been created, but notice that it is not active yet until we do a ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"display"})})," or ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"writeStream"})})," operation",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We will enrich our raw data with additional metadata describing the source file and the time it was ingested"]}),"\n",(0,t.jsxs)(s.admonition,{type:"info",children:[(0,t.jsx)(s.p,{children:"Such information is useful for troubleshooting errors if corrupted data is encountered."}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{4-5}",children:"CREATE OR REPLACE TEMPORARY VIEW orders_tmp AS (\r\n    SELECT \r\n        *,\r\n        current_timestamp(),\r\n        input_file_name() AS source_file\r\n    FROM orders_raw_temp\r\n\r\n)\n"})})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us take a look on our enriched raw data"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"SELECT * FROM orders_tmp\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Our stream is active now, and we can see that we have successfully inserted the data with the metadata of the arrival time and the source file",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us cancel this stream for now",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We are going to pass this enriched data back to PySpark API to process an incremental write to a Delta Lake table called ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"orders_bronze"})})]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'spark.table(\r\n    "orders_tmp"\r\n).writeStream.format(\r\n    "delta"\r\n).option(\r\n    "checkpointLocation",\r\n    "dbfs:/mnt/demo/checkpoints/orders_bronze"\r\n).outputMode(\r\n    "append"\r\n).table("orders_bronze")\n'})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Our ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"writeStream"})})," is active now, and we can see that it has started processing our data",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us check how many records were written into the bronze table"]}),"\n",(0,t.jsxs)(s.admonition,{type:"info",children:[(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"SELECT COUNT(*) FROM orders_bronze\n"})}),(0,t.jsx)(s.p,{children:"3000 records have been written corresponding to our three files, where each file contain 1000 records"})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We can trigger another file arrival using the following function"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"load_new_data()\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us come back to our active stream and see what is happening. We see that the new data is immediately detected by the streaming query",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We can confirm this by querying the number of records again in our table"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"how-to-implement-the-silver-layer",children:"How to implement the silver layer"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We can move on to work on our second hop, the silver layer"]}),"\n"]}),"\n",(0,t.jsx)(s.h3,{id:"create-a-new-temporary-view-from-json-files",children:"Create a new temporary view from JSON files"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Here we are creating a customers static temporary view from JSON files",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We are doing it with PySpark API, but we can also do it with Spark SQL"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'spark.read.format(\r\n    "json"\r\n).load(\r\n    f"{dataset_bookstore}/customers-json"\r\n).createOrReplaceTempView(\r\n    "customers_lookup"\r\n)\n'})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us take a look at our ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"customers_lookup"})})," temporary view"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"SELECT * FROM customers_lookup\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Here we have 3 columns:",(0,t.jsx)("br",{})]}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["The customer ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"id"})})," that we will use it for joining the data;",(0,t.jsx)("br",{})]}),"\n",(0,t.jsxs)(s.li,{children:["The customer ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"email"})}),";",(0,t.jsx)("br",{})]}),"\n",(0,t.jsxs)(s.li,{children:["The ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"profile"})})," information as a complex JSON object",(0,t.jsx)("br",{})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h3,{id:"create-a-streaming-temporary-view-from-an-existing-table",children:"Create a streaming temporary view from an existing table"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","To work on our bronze data in the silver layer, we will start by creating a streaming temporary view against our bronze table"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'spark.readStream.table(\r\n    "orders_bronze"\r\n).createOrReplaceTempView(\r\n    "orders_bronze_tmp"\r\n)\n'})})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h3,{id:"combine-orders-with-customers-data",children:"Combine orders with customers data"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","In this silver level, we are doing several enrichments and checks",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We join the order data with the customers information to add customers names"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{6-7,16-17}",children:"CREATE OR REPLACE TEMPORARY VIEW orders_enriched_tmp AS (\r\n    SELECT \r\n        order_id,\r\n        quantity,\r\n        o.customer_id,\r\n        c.profile:first_name AS f_name,\r\n        c.profile:last_name AS l_name,\r\n        CAST(\r\n            from_unixtime(\r\n                order_timestamp, \r\n                'yyyy-MM-dd HH:mm:ss'\r\n            ) AS timestamp\r\n        ) AS order_timestamp,\r\n        books\r\n    FROM orders_bronze_tmp AS o\r\n    INNER JOIN customers_lookup c\r\n    ON o.customer_id = c.customer_id\r\n    WHERE quantity > 0\r\n)\n"})})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h3,{id:"parse-unix-timestamp-into-human-readable-format",children:"Parse Unix timestamp into human-readable format"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We parse the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"order_timestamp"})})," from Unix timestamp into human readable format"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{8-13}",children:"CREATE OR REPLACE TEMPORARY VIEW orders_enriched_tmp AS (\r\n    SELECT \r\n        order_id,\r\n        quantity,\r\n        o.customer_id,\r\n        c.profile:first_name AS f_name,\r\n        c.profile:last_name AS l_name,\r\n        CAST(\r\n            from_unixtime(\r\n                order_timestamp, \r\n                'yyyy-MM-dd HH:mm:ss'\r\n            ) AS timestamp\r\n        ) AS order_timestamp,\r\n        books\r\n    FROM orders_bronze_tmp AS o\r\n    INNER JOIN customers_lookup c\r\n    ON o.customer_id = c.customer_id\r\n    WHERE quantity > 0\r\n)\n"})})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h3,{id:"exclude-orders-without-items",children:"Exclude orders without items"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We exclude any order with no items"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{18}",children:"CREATE OR REPLACE TEMPORARY VIEW orders_enriched_tmp AS (\r\n    SELECT \r\n        order_id,\r\n        quantity,\r\n        o.customer_id,\r\n        c.profile:first_name AS f_name,\r\n        c.profile:last_name AS l_name,\r\n        CAST(\r\n            from_unixtime(\r\n                order_timestamp, \r\n                'yyyy-MM-dd HH:mm:ss'\r\n            ) AS timestamp\r\n        ) AS order_timestamp,\r\n        books\r\n    FROM orders_bronze_tmp AS o\r\n    INNER JOIN customers_lookup c\r\n    ON o.customer_id = c.customer_id\r\n    WHERE quantity > 0\r\n)\n"})})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h3,{id:"create-a-writestream-to-persist-data-into-a-silver-table",children:"Create a writeStream to persist data into a silver table"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us do a ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"writeStream"})})," for this ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"orders_enriched_tmp"})})," data into a silver table"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'spark.table(\r\n    "orders_enriched_tmp"\r\n).writeStream.format(\r\n    "delta"\r\n).option(\r\n    "checkpointLocation",\r\n    "dbfs:/mnt/demo/checkpoints/orders_silver"\r\n).outputMode(\r\n    "append"\r\n).table(\r\n    "orders_silver"\r\n)\n'})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","The data has been processed with the stream. Let's query our silver table"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"SELECT * FROM orders_silver\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us now check how many records do we have?"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"SELECT COUNT(*) FROM orders_silver\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us trigger another new file and wait for it to propagate through the previous two streams, from bronze to silver layer"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"load_new_data()\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us see our stream dashboard. The new data has been received. Let us check the counts in the silver table"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"SELECT COUNT(*) FROM orders_silver\n"})})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"how-to-implement-the-gold-layer",children:"How to implement the gold layer"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us now work on the gold layer",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We need a stream of data from the silver table into a streaming temporary view"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'spark.readStream.table(\r\n    "orders_silver"\r\n).createOrReplaceTempView(\r\n    "orders_silver_tmp"\r\n)\n'})})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h3,{id:"how-to-aggregate-data-from-a-streaming-data-source",children:"How to aggregate data from a streaming data source"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We write another stream to create an aggregate gold table for the daily number of books for each customer"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:'CREATE OR REPLACE TEMP VIEW daily_customer_books_tmp AS (\r\n    SELECT\r\n        customer_id,\r\n        f_name,\r\n        l_name,\r\n        date_trunc(\r\n            "DD",\r\n            order_timestamp\r\n        ) AS order_date,\r\n        SUM(quantity) AS books_counts\r\n    FROM orders_silver_tmp\r\n    GROUP BY \r\n        customer_id, \r\n        f_name,\r\n        l_name,\r\n        date_trunc(\r\n            "DD", \r\n            order_timestamp\r\n        )\r\n)\n'})})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h3,{id:"how-to-persist-aggregated-data-into-the-gold-table",children:"How to persist aggregated data into the gold table"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us write this aggregated data into a gold table called ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"daily_customer_books"})})]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'spark.table(\r\n    "daily_customer_books_tmp"\r\n).writeStream.format(\r\n    "delta"\r\n).outputMode(\r\n    "complete"\r\n).option(\r\n    "checkpointLocation",\r\n    "dbfs:/mnt/demo/checkpoints/daily_customer_books"\r\n).trigger(\r\n    availableNow=True\r\n).table(\r\n    "daily_customer_books"\r\n)\n'})})}),"\n",(0,t.jsx)(s.admonition,{type:"note",children:(0,t.jsxs)(s.p,{children:["The stream stopped on its own after processing all the available data in micro batches. This is because we are using trigger ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"availableNow"})})," option"]})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","With this way, we can combine streaming and batch workloads in the same pipeline",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We are also using the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"complete"})})," output mode to rewrite the updated aggregation each time our logic runs"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.p,{children:"Keep in mind that Structured Streaming assumes data is only being appended in the upstream tables. Once a table is updated or overwritten, it is no longer valid for streaming"})}),"\n",(0,t.jsx)(s.admonition,{type:"note",children:(0,t.jsx)(s.p,{children:"In our case here, we cannot read a stream from this gold table"})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","To change this behavior, you can set options like ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"ignoreChanges"})}),", but they have other limitations",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us now query the gold table"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"SELECT * FROM daily_customer_books\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Here we can see our aggregated data. Customers currently have books counts between 5 and 10",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us finally land all the remaining data files in our source directory"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"load_new_data(all=True)\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","The data will be propagated from our source directory into the bronze, silver layer, until the gold layer",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","For the gold layer, we need to rerun our final query to update the gold table. Since the query is configured as a batch job using the trigger ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"availableNow"})})," syntax",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us rerun this stream query"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'spark.table(\r\n    "daily_customer_books_tmp"\r\n).writeStream.format(\r\n    "delta"\r\n).outputMode(\r\n    "complete"\r\n).option(\r\n    "checkpointLocation",\r\n    "dbfs:/mnt/demo/checkpoints/daily_customer_books"\r\n).trigger(\r\n    availableNow=True\r\n).table(\r\n    "daily_customer_books"\r\n)\n'})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","All the available data has been processed. Let us confirm this by re-query our gold table"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"SELECT * FROM daily_customer_books\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Now we can see customers having more books counts after processing the new changes"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"cleanup",children:"Cleanup"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us end up by stopping all the active streams by running this ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"for"})})," loop"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'for stream in spark.streams.active:\r\n    print("Stopping stream: " + stream.id)\r\n    stream.stop()\r\n    stream.awaitTermination()\n'})})}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,s,n)=>{n.d(s,{R:()=>a,x:()=>l});var t=n(6540);const r={},i=t.createContext(r);function a(e){const s=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function l(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(i.Provider,{value:s},e.children)}}}]);