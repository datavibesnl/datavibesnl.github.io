"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[5456],{8258:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>l});var t=n(4848),i=n(8453);const r={},o="3.4 Advanced Transformations (HandsOn)",a={id:"Databricks Certified Data Engineer Associate - Preparation/ELT with Spark SQL and Python/3.4 Advanced Transformations Hands On",title:"3.4 Advanced Transformations (HandsOn)",description:"Introduction",source:"@site/docs/Databricks Certified Data Engineer Associate - Preparation/3. ELT with Spark SQL and Python/3.4 Advanced Transformations Hands On.md",sourceDirName:"Databricks Certified Data Engineer Associate - Preparation/3. ELT with Spark SQL and Python",slug:"/Databricks Certified Data Engineer Associate - Preparation/ELT with Spark SQL and Python/3.4 Advanced Transformations Hands On",permalink:"/docs/Databricks Certified Data Engineer Associate - Preparation/ELT with Spark SQL and Python/3.4 Advanced Transformations Hands On",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"3.3 Writing to Tables (Hands On)",permalink:"/docs/Databricks Certified Data Engineer Associate - Preparation/ELT with Spark SQL and Python/3.3 Writing to Tables Hands On"},next:{title:"3.5 Higher Order Functions and SQL UDFs",permalink:"/docs/Databricks Certified Data Engineer Associate - Preparation/ELT with Spark SQL and Python/3.5 Higher Order Functions and SQL UDFs"}},c={},l=[{value:"Introduction",id:"introduction",level:2},{value:"Dataset setup",id:"dataset-setup",level:2},{value:"Explore nested data structures",id:"explore-nested-data-structures",level:2},{value:"How to interact with nested JSON structures in tables",id:"how-to-interact-with-nested-json-structures-in-tables",level:2},{value:"Use the <strong><code>:</code></strong> syntax to interact with nested data structures",id:"use-the--syntax-to-interact-with-nested-data-structures",level:3},{value:"Use the <strong><code>from_json</code></strong> function to interact with nested data structures",id:"use-the-from_json-function-to-interact-with-nested-data-structures",level:3},{value:"How to derive the schema from existing data",id:"how-to-derive-the-schema-from-existing-data",level:4},{value:"How to use existing data as a schema",id:"how-to-use-existing-data-as-a-schema",level:4},{value:"How to interact with nested object using a <strong><code>struct</code></strong> type",id:"how-to-interact-with-nested-object-using-a-struct-type",level:4},{value:"How to interact with subfields using a struct type",id:"how-to-interact-with-subfields-using-a-struct-type",level:4},{value:"How to flatten fields into columns from a nested data structure with <strong><code>*</code></strong> operation",id:"how-to-flatten-fields-into-columns-from-a-nested-data-structure-with--operation",level:2},{value:"How to put each element of an array on its own row with <strong><code>explode</code></strong> function",id:"how-to-put-each-element-of-an-array-on-its-own-row-with-explode-function",level:2},{value:"How to collect unique values from a field (including fields within an array) with <strong><code>collect_set</code></strong> function",id:"how-to-collect-unique-values-from-a-field-including-fields-within-an-array-with-collect_set-function",level:2},{value:"How to keep only the distinct values from an array",id:"how-to-keep-only-the-distinct-values-from-an-array",level:2},{value:"JOIN operations in Spark SQL",id:"join-operations-in-spark-sql",level:2},{value:"How to use set operations in Spark SQL",id:"how-to-use-set-operations-in-spark-sql",level:2},{value:"How to use <strong><code>UNION</code></strong> in Spark SQL",id:"how-to-use-union-in-spark-sql",level:3},{value:"How to use <strong><code>INTERSECT</code></strong> in Spark SQL",id:"how-to-use-intersect-in-spark-sql",level:3},{value:"How to use <strong><code>MINUS</code></strong> in Spark SQL",id:"how-to-use-minus-in-spark-sql",level:3},{value:"How to use <strong><code>PIVOT</code></strong> in Spark SQL",id:"how-to-use-pivot-in-spark-sql",level:3}];function d(e){const s={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.h1,{id:"34-advanced-transformations-handson",children:"3.4 Advanced Transformations (HandsOn)"}),"\n",(0,t.jsx)(s.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","In this notebook, we are going to explore advanced transformations present in Spark SQL",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We will continue using our bookstore dataset, with its 3 tables:"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.ol,{children:["\n",(0,t.jsx)(s.li,{children:"Customers;"}),"\n",(0,t.jsx)(s.li,{children:"Orders;"}),"\n",(0,t.jsx)(s.li,{children:"Books"}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"dataset-setup",children:"Dataset setup"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us start by running the copy dataset notebook"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sh",children:"%run ../Includes/Copy-Datasets\n"})})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"explore-nested-data-structures",children:"Explore nested data structures"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","If we query our customer data, we see that we have several columns",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","One of them is the profile information of the customer. It has a complex data structure, which is a nested JSON string",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","As you can see the address itself is a JSON string that contains:"]}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:"Street;"}),"\n",(0,t.jsx)(s.li,{children:"City"}),"\n",(0,t.jsxs)(s.li,{children:["Country",(0,t.jsx)("br",{})]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us run ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"DESCRIBE"})})," command on our table"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"DESCRIBE customers\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","As you can see, the profile here is nothing but a string. It's a JSON string"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"how-to-interact-with-nested-json-structures-in-tables",children:"How to interact with nested JSON structures in tables"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Spark SQL has built-in functionality to directly interact with JSON data stored as strings"]}),"\n"]}),"\n",(0,t.jsxs)(s.h3,{id:"use-the--syntax-to-interact-with-nested-data-structures",children:["Use the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:":"})})," syntax to interact with nested data structures"]}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We can simply use the colon (",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:":"})}),") syntax to traverse nested data structures",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Here we are accessing the first name of the profile. In the same way we can access the nested value of the country from the address of the profile"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{3-4}",children:"SELECT \n    customer_id, \n    profile:first_name,\n    profile:address:country\nFROM customers\n"})})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.h3,{id:"use-the-from_json-function-to-interact-with-nested-data-structures",children:["Use the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"from_json"})})," function to interact with nested data structures"]}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Spark has also the ability to parse JSON object into ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"struct"})})," types"]}),"\n",(0,t.jsxs)(s.admonition,{type:"info",children:[(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"struct"})})," is a native spark type with nested attributes. This can be done with the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"from_json"})})," function."]}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{2}",children:"SELECT \n    from_json(profile) AS profile_struct\nFROM customers;\n"})})]}),"\n",(0,t.jsx)(s.admonition,{type:"warning",children:(0,t.jsx)(s.p,{children:"This function requires the schema of the JSON object"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"how-to-derive-the-schema-from-existing-data",children:"How to derive the schema from existing data"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We can derive the schema from our current data"]}),"\n",(0,t.jsxs)(s.admonition,{type:"info",children:[(0,t.jsx)(s.p,{children:"For this we need a sample data of our JSON value with non-null fields"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"SELECT\n    profile\nFROM customers\nLIMIT 1\n"})})]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"how-to-use-existing-data-as-a-schema",children:"How to use existing data as a schema"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We can copy this sample data and provide it to the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"schema_of_json"})})," function. And we will store this parsed record in a temporary view"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{6-17}",children:'CREATE OR REPLACE TEMP VIEW parsed_customers AS \nSELECT \n    customer_id,\n    from_json(\n        profile, \n        schema_of_json(\n            \'{\n                "first_name": "Thomas",\n                "last_name": "Lane",\n                "gender": "Male",\n                "address": {\n                    "street": "06 Boulevard Victor Hugo",\n                    "city": "Paris",\n                    "country": "France"\n                }\n            }\'\n        ) \n    ) as profile_struct\nFROM customers;\n\nSELECT * FROM parsed_customers;\n'})})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.h4,{id:"how-to-interact-with-nested-object-using-a-struct-type",children:["How to interact with nested object using a ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"struct"})})," type"]}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","The first thing to notice when you work with a ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"struct"})})," type is the ability to interact with the nested object",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us see some more details. As you can see, this new column ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"profile_struct"})})," has a ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"struct"})})," datatype where the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"address"})})," field also is of a ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"struct"})})," type"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"DESCRIBE parsed_customers\n"})})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"how-to-interact-with-subfields-using-a-struct-type",children:"How to interact with subfields using a struct type"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","With ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"struct"})})," type, we can interact with the subfields using standard period or dot (",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"."})}),") syntax instead of the colon (",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:":"})}),") syntax we use for the JSON string",(0,t.jsx)("br",{})]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"SELECT\n    customer_id,\n    profile_struct.first_name,\n    profile_struct.address.country\nFROM parsed_customers\n"})})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.h2,{id:"how-to-flatten-fields-into-columns-from-a-nested-data-structure-with--operation",children:["How to flatten fields into columns from a nested data structure with ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"*"})})," operation"]}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Once a JSON string is converted to a ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"struct"})})," type, we can use the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"*"})})," operation to flatten fields into columns"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{4}",children:"CREATE OR REPLACE TEMP VIEW customers_final AS \nSELECT \n    customer_id, \n    profile_struct.*\nFROM parsed_customers;\n\nSELECT * FROM customers_final\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","As you can see here, the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"first_name"})}),", ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"last_name"})}),", ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"gender"})})," and the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"address"})})," itself are all now separate columns"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.h2,{id:"how-to-put-each-element-of-an-array-on-its-own-row-with-explode-function",children:["How to put each element of an array on its own row with ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"explode"})})," function"]}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us now switch to our ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"orders"})})," tables to see another interesting feature, which is the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"explode"})})," function",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us first explore again some fields of our table"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{4}",children:"SELECT \n    orders_id, \n    customers_id,\n    books\nFROM orders\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Here, the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"books"})})," column is an array of ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"struct"})})," type",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Spark SQL has a number of functions specifically to deal with arrays",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","The most important one is the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"explode"})})," function that allows us to put each element of an array on its own row",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Each element of the book's array has its own row and we are repeating the other information like the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"customer_id"})})," and the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"order_id"})})]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"SELECT \n    order_id, \n    customer_id,\n    explode(books) AS book\nFROM orders\n"})})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.h2,{id:"how-to-collect-unique-values-from-a-field-including-fields-within-an-array-with-collect_set-function",children:["How to collect unique values from a field (including fields within an array) with ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"collect_set"})})," function"]}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Another interesting function is the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"collect_set"})})," aggregation function that allows us to collect unique values for a field, including fields within arrays",(0,t.jsx)("br",{})]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{3-4}",children:"SELECT\n    customer_id,\n    collect_set(order_id) AS orders_set,\n    collect_set(books.book_id) AS book_set\nFROM orders\nGROUP BY customer_id\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","As you can see here, the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"books_set"})})," column is actually an array of array",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","The question, can we flatten this array? Yes, we can"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"how-to-keep-only-the-distinct-values-from-an-array",children:"How to keep only the distinct values from an array"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","In addition, we can also keep only the distinct values as, for example, for the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"B08"})})," that is exist in 2 elements of the array"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsxs)(s.p,{children:["Instead of having the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"B08"})})," twice after flatten the array, we will get only one unique value"]})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Here we are applying ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"flatten"})})," function and then we apply the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"array_distinct"})})," function to keep only the distinct values. And here we can see the final results before and after"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{3-7}",children:"SELECT\n    collect_set(books.book_id) AS before_flatten,\n    array_distinct(\n        flatten(\n            collect_set(books.book_id)\n        )\n    )\nFROM orders\nGROUP BY customer_id\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Here we can see the final results before and after"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"join-operations-in-spark-sql",children:"JOIN operations in Spark SQL"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Let us now switch to join operations",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Spark SQL supports standard join operations:"]}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"INNER"})}),";"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"OUTER"})}),";"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"LEFT"})}),";"]}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"RIGHT"})})}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"Cross joins"})}),(0,t.jsx)("br",{})]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Here we  are joining the result of the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"explode"})})," operation to the books lookup table in order to retrieve books information like ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"books"})}),", ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"title"})}),", and author's ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"name"})}),".",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We simply specify the type of the operation to apply. In our case, it's an inner join based on the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"book_id"})})," key",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We are storing the results in a view called ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"orders_enriched"})})]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{9-10}",children:"CREATE OR REPLACE VIEW orders_enriched AS\nSELECT *\nFROM (\n    SELECT \n        *,\n        explode(books) AS book\n    FROM orders\n) o\nINNER JOIN books b\nON o.book.book_id = b.book_id;\n\nSELECT * FROM orders_enriched\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","As you can see, we are grabbing for each book the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"title"})})," and the author ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"name"})})," and the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"category"})})," for this book"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"how-to-use-set-operations-in-spark-sql",children:"How to use set operations in Spark SQL"}),"\n",(0,t.jsxs)(s.h3,{id:"how-to-use-union-in-spark-sql",children:["How to use ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"UNION"})})," in Spark SQL"]}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Spark SQL also supports set operations like ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"UNION"})})]}),"\n",(0,t.jsxs)(s.admonition,{type:"info",children:[(0,t.jsxs)(s.p,{children:["For example, we can ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"UNION"})})," the old and the new data of the orders table"]}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"CREATE OR REPLACE TEMP VIEW orders_updates \nAS SELECT \n    *\nFROM parquet.`${dataset.bookstore}/orders-new`;\n\nSELECT\n    *\nFROM orders\nUNION\nSELECT \n    *\nFROM orders_updates\n"})})]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.h3,{id:"how-to-use-intersect-in-spark-sql",children:["How to use ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"INTERSECT"})})," in Spark SQL"]}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","In the same way we can do ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"INTERSECT"})})," operation"]}),"\n",(0,t.jsxs)(s.admonition,{type:"info",children:[(0,t.jsxs)(s.p,{children:["The ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"INTERSECT"})})," command returns all rows found in both relations"]}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"SELECT * FROM orders\nINTERSECT\nSELECT * FROM orders_updates\n"})})]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.h3,{id:"how-to-use-minus-in-spark-sql",children:["How to use ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"MINUS"})})," in Spark SQL"]}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","If you are ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"orders MINUS orders_updates"})}),", you will get only the orders data without the 700 new records",(0,t.jsx)("br",{})]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",children:"SELECT * FROM orders\nMINUS\nSELECT * FROM orders_updates\n"})})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.h3,{id:"how-to-use-pivot-in-spark-sql",children:["How to use ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"PIVOT"})})," in Spark SQL"]}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Spark SQL also support ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"PIVOT"})})," clause, which is used to change data perspective",(0,t.jsx)("br",{})]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","We can get the aggregated values based on a specific column values, which will be turned to multiple columns used in ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"SELECT"})})," clause"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsxs)(s.p,{children:["We here we have ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"SELECT * FROM"})})," and we specify between two parentheses the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"SELECT"})})," statement that we will be the input for this table"]})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","In the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"PIVOT"})})," clause, the first argument is an aggregation function (",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"SUM"})}),", ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"AVG"})}),", ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"MAX"})}),", etc.), and the column to be aggregated."]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{9}",children:"CREATE OR REPLACE TABLE transactions AS\nSELECT * FROM (\n    SELECT\n        customer_id, \n        book.book_id AS book_id,\n        book.quantity AS quantity\n    FROM orders_enriched\n) PIVOT (\n    SUM(quantity) \n    FOR book_id IN (\n        'B01',\n        'B02', \n        'B03',\n        'B04',\n        'B05',\n        'B06',\n        'B07',\n        'B08',\n        'B09',\n        'B10',\n        'B11',\n        'B12',     \n    )\n);\n\nSELECT * FROM transactions\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Then we specify the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"PIVOT"})})," column in the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"FOR"})})," subclause. The ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"IN"})})," operator contains the pivot column values"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-sql",metastring:"{10-22}",children:"CREATE OR REPLACE TABLE transactions AS\nSELECT * FROM (\n    SELECT\n        customer_id, \n        book.book_id AS book_id,\n        book.quantity AS quantity\n    FROM orders_enriched\n) PIVOT (\n    SUM(quantity) \n    FOR book_id IN (\n        'B01',\n        'B02', \n        'B03',\n        'B04',\n        'B05',\n        'B06',\n        'B07',\n        'B08',\n        'B09',\n        'B10',\n        'B11',\n        'B12',     \n    )\n);\n\nSELECT * FROM transactions\n"})})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Here we use the ",(0,t.jsx)(s.strong,{children:(0,t.jsx)(s.code,{children:"PIVOT"})})," command to create a new transaction table that flatten out the information contained in the orders table for each customer"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.p,{children:"Such a flatten data format can be useful for dashboarding, but also useful for applying machine learning algorithms for inference and predictions"})}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,s,n)=>{n.d(s,{R:()=>o,x:()=>a});var t=n(6540);const i={},r=t.createContext(i);function o(e){const s=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function a(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),t.createElement(r.Provider,{value:s},e.children)}}}]);