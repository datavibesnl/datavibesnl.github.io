# 3.3 Writing to Tables (Hands On)

- [ ] In this notebook, we are going to explore SQL syntax to insert and update records in Delta Tables

    :::info
        Remember Delta technology provides ACID compliant updates to Delta tables
    :::

- [ ] We will continue working with our bookstore dataset. Let us first run our helping notebook to copy the dataset

    :::info
        ```sh
        %run ../Includes/Copy-Datasets
        ```
    :::

- [ ] We will use a **`CTAS`** statement to create orders delta table as **`SELECT`** statement from parquet files

    :::info
        ```sql
        CREATE TABLE orders AS
        SELECT * FROM parquet.`${dataset.bookstore}/orders`
        ```
    :::

- [ ] As you can see, parquet files have a well-defined schema, so we managed to extract the data correctly

    :::info
        ```sql
        SELECT * FROM orders
        ```
    :::

- [ ] When writing to tables, we could be interested by completely overwriting the data in the table

## Benefits of overwriting tables instead of deleting

- [ ] There are multiple benefits to overwriting tables instead of deleting and recreating tables

    :::info
        For example, the old version of the table still exists and can easily retrieve all data using Time Travel
    :::

- [ ] Overwriting a table is much faster because it does not need to list the directory recursively or delete any files<br/>

- [ ] Concurrent queries can still read the table while you are overwriting it

    :::info
        Due to the ACID transaction guarantees, if overwriting the table fails, the table will be in its previous state
    :::

## How to overwrite existing tables

### Overwrite tables with **`CREATE OR REPLACE`**

- [ ] The first method to accomplish complete overwrite is to use **`CREATE OR REPLACE TABLE`**

    :::info
        ```sql
        CREATE OR REPLACE TABLE orders AS
        SELECT * FROM parquet.`${dataset.bookstore}/orders`
        ```
    :::

- [ ] **`CREATE OR REPLACE TABLE`** statements fully replace the content of a table each time they execute<br/>

- [ ] Let us now check our table history

    :::info
        ```sql
        DESCRIBE HISTORY orders
        ```
    :::

- [ ] As you can see, the version **`0`** is a **`CREATE TABLE AS SELECT`** statement. While **`CREATE OR REPLACE`** statement has generated a new table version

### Overwrite tables with **`INSERT OVERWRITE`**

- [ ] The second method to overwrite table data is to use **`INSERT OVERWRITE`** statement. It provide a nearly identical output as above

    :::info
        ```sql
        INSERT OVERWRITE orders
        SELECT * FROM parquet.`${dataset.bookstore}/orders`
        ```

        It means data in the target table will be replaced by data from the query
    :::

- [ ] **`INSERT OVERWRITE`** statement has some differences

    :::info
        For example, it can only overwrite an existing table and not creating a new one like our **`CREATE OR REPLACE`** statement
    :::

- [ ] It can override only the new records that match the current table schema, which means that it is a safer technique for overwriting an existing table without the risk of modifying the table schema

    :::info
        ```sql
        INSERT OVERWRITE orders
        SELECT * FROM parquet.`${dataset.bookstore}/orders`
        ```
    :::

- [ ] We can see our table history

    :::info
        ```sql
        DESCRIBE HISTORY orders
        ```
    :::

- [ ] As you can see here, the **`INSERT OVERWRITE`** operation has been recorded as a new version in the table as WRITE operation<br/>

- [ ] If you try to insert overwrite the data with different schema, for example, here we are adding a new column of the data for the current timestamp<br/>

    ::::warning
        By running this command, we see that it generates an exception

        :::info
            ```sql
            INSERT OVERWRITE orders
            SELECT *, current_timestamp() 
            FROM parquet.`${dataset.bookstore}/orders`
            ```
        

        The exception says a schema mismatch detected when writing to the Delta table
    ::::

    :::tip
        The way how they enforce schema on-write is the primary difference between **`INSERT OVERWRITE`** and **`CREATE OR REPLACE TABLE`** statements
    :::

## How to add records to an existing table

- [ ] Let us now talk about appending records to tables. The easiest method is to use **`INSERT INTO`** statement<br/>

- [ ] Here we are inserting a new data using an input query that query the parquet files in the orders-new directory<br/>

- [ ] We have successfully added 700 new records to our table. And we can check the new number of orders

    :::info
        ```sql
        INSERT INTO orders
        SELECT * FROM parquet.`${dataset.bookstore}/orders-new`
        ```
    :::

## How to prevent the same records from being inserted with **`MERGE`**

- [ ] The **`INSERT INTO`** statement is a simple and efficient operation for inserting new data. However, it does not have any built in guarantees to prevent inserting the same records multiple times

    :::info
        It means re-executing the query will write the same records to the target table resulting in duplicate records
    :::

- [ ] To resolve this issue, we can use our second method, which is **`MERGE`** INTO statement<br/>

- [ ] With the **`MERGE`** statement, you can *upsert* data from a source table, view, or dataframe into the target data table

    :::info
        It means you can insert, update and delete using the **`MERGE`** INTO statements
    :::

- [ ] Here we will use the **`MERGE`** operation to update the customer data with updated emails and adding new customers<br/>

- [ ] We are creating a temporary view of the new customer data

    :::info
        ```sql {1-2}
        CREATE OR REPLACE TEMP VIEW customers_updates AS
        SELECT * FROM json.`${dataset.bookstore}/customers-json-new`;
        
        MERGE INTO customers c
        USING customers_updates u
        ON c.customer_id = u.customer_id
        WHEN MATCHED AND c.email and u.email IS NOT NULL THEN
            UPDATE SET email = u.email, updated = u.updated
        WHEN NOT MATCHED THEN INSERT *
        ```
    :::

- [ ] We can apply the **`MERGE`** operation that says **`MERGE INTO`** customers the new changes coming from **`customer_updates`** **`TEMP VIEW`** on the **`customer_id`** key

    :::info
        ```sql {4-6}
        CREATE OR REPLACE TEMP VIEW customers_updates AS
        SELECT * FROM json.`${dataset.bookstore}/customers-json-new`;
        
        MERGE INTO customers c
        USING customers_updates u
        ON c.customer_id = u.customer_id
        WHEN MATCHED AND c.email and u.email IS NOT NULL THEN
            UPDATE SET email = u.email, updated = u.updated
        WHEN NOT MATCHED THEN INSERT *
        ```
    :::

- [ ] We have two actions here. When **`MATCH`**, we do an **`UPDATE`** and when **`NOT MATCH`**, we do an **`INSERT`**. In addition, we add extra conditions<br/>

- [ ] In this case, we are checking that the current row has a **`NULL`** email while the new record does not. In such a case, we **`UPDATE`** the email and we also update the last **`updated`** timestamp<br/>

- [ ] If the new record does not match any existing customers based on the **`customer_id`**, in this case, we will insert this new record.

    :::info
        ```sql {7-9}
        CREATE OR REPLACE TEMP VIEW customers_updates AS
        SELECT * FROM json.`${dataset.bookstore}/customers-json-new`;
        
        MERGE INTO customers c
        USING customers_updates u
        ON c.customer_id = u.customer_id
        WHEN MATCHED AND c.email and u.email IS NOT NULL THEN
            UPDATE SET email = u.email, updated = u.updated
        WHEN NOT MATCHED THEN INSERT *
        ```
    :::

- [ ] As we can see here, we have updated 100 records and we have inserted 201 records. And no records have been deleted

## How to avoid duplicates when inserting records with **`MERGE`**

- [ ] In a **`MERGE`** operation, updates, inserts and deletes are completed in a single atomic transaction<br/>

- [ ] **`MERGE`** operation is a great solution for avoiding duplicates when inserting records

### Create a temporary view from CSV files

- [ ] Let us see another example. Here we have new books to be inserted and they are coming in CSV Format<br/>

- [ ] We will create this temporary view (**`TEMP VIEW`**) against this new data

    :::info
        ```sql {1-12}
        CREATE OR REPLACE TEMP VIEW books_updates (
            book_id STRING,
            title STRING,
            author STRING,
            category STRING,
            price DOUBLE
        ) USING CSV
        OPTIONS (
            path="${dataset.bookstore}/books-csv-new",
            header="true",
            delimiter=";"
        );
        
        SELECT * FROM books_updates
        ```
    :::

- [ ] Here we have first new books and we are only interested by inserting the computer science books in our database

### Update delta table from temporary view

- [ ] Let us now use the **`MERGE INTO`** statement to update the table books with the data coming from the temporary view books_updates<br/>

- [ ] We can use the **`MERGE INTO`** statement where we provide only the **`NOT MATCH`** condition

    :::info
        It means we are only inserting new data if they are not already exist based on our key, which is the book_id and the title
    :::

- [ ] We are specifying the category of the new record to be inserted is only Computer Science

    :::info
        ```sql
        **`MERGE`** INTO books b
        USING books_updates u
        ON b.book_id = u.book_id AND b.title = u.title
        WHEN NOT MATCHED AND u.category = 'Computer Science' THEN
            INSERT *
        ```
    :::

- [ ] As expected, we are only inserting three new records, which are the 3 computer science books<br/>

- [ ] One of the main benefits of the **`MERGE`** operation is to avoid duplicate<br/>

- [ ] If we try to rerun this statement, it will not re-insert those records as they are already on the table