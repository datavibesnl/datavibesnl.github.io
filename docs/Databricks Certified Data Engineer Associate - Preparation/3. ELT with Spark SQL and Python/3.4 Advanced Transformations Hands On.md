# 3.4 Advanced Transformations (HandsOn)

## Introduction

- [ ] In this notebook, we are going to explore advanced transformations present in Spark SQL<br/>

- [ ] We will continue using our bookstore dataset, with its 3 tables: 

1. Customers;
2. Orders;
3. Books

## Dataset setup

- [ ] Let us start by running the copy dataset notebook

    :::info
        ```sh
        %run ../Includes/Copy-Datasets
        ```
    :::

## Explore nested data structures 

- [ ] If we query our customer data, we see that we have several columns<br/>

- [ ] One of them is the profile information of the customer. It has a complex data structure, which is a nested JSON string<br/>

- [ ] As you can see the address itself is a JSON string that contains:

    - Street; 
    - City 
    - Country<br/>

- [ ] Let us run **`DESCRIBE`** command on our table

    :::info
        ```sql
        DESCRIBE customers
        ```
    :::

- [ ] As you can see, the profile here is nothing but a string. It's a JSON string

## How to interact with nested JSON structures in tables

- [ ] Spark SQL has built-in functionality to directly interact with JSON data stored as strings

### Use the **`:`** syntax to interact with nested data structures

- [ ] We can simply use the colon (**`:`**) syntax to traverse nested data structures<br/>

- [ ] Here we are accessing the first name of the profile. In the same way we can access the nested value of the country from the address of the profile

    :::info
        ```sql {3-4}
        SELECT 
            customer_id, 
            profile:first_name,
            profile:address:country
        FROM customers
        ```
    :::

### Use the **`from_json`** function to interact with nested data structures

- [ ] Spark has also the ability to parse JSON object into **`struct`** types

    :::info
        **`struct`** is a native spark type with nested attributes. This can be done with the **`from_json`** function.

        ```sql {2}
        SELECT 
            from_json(profile) AS profile_struct
        FROM customers;
        ```
    :::

    :::warning
        This function requires the schema of the JSON object
    :::

#### How to derive the schema from existing data

- [ ] We can derive the schema from our current data

    :::info
        For this we need a sample data of our JSON value with non-null fields

        ```sql
        SELECT
            profile
        FROM customers
        LIMIT 1
        ```
    :::

#### How to use existing data as a schema

- [ ] We can copy this sample data and provide it to the **`schema_of_json`** function. And we will store this parsed record in a temporary view

    :::info
        ```sql {6-17}
        CREATE OR REPLACE TEMP VIEW parsed_customers AS 
        SELECT 
            customer_id,
            from_json(
                profile, 
                schema_of_json(
                    '{
                        "first_name": "Thomas",
                        "last_name": "Lane",
                        "gender": "Male",
                        "address": {
                            "street": "06 Boulevard Victor Hugo",
                            "city": "Paris",
                            "country": "France"
                        }
                    }'
                ) 
            ) as profile_struct
        FROM customers;
        
        SELECT * FROM parsed_customers;
        ```
    :::

#### How to interact with nested object using a **`struct`** type

- [ ] The first thing to notice when you work with a **`struct`** type is the ability to interact with the nested object<br/>

- [ ] Let us see some more details. As you can see, this new column **`profile_struct`** has a **`struct`** datatype where the **`address`** field also is of a **`struct`** type

    :::info
        ```sql
        DESCRIBE parsed_customers
        ```
    :::

#### How to interact with subfields using a struct type

- [ ] With **`struct`** type, we can interact with the subfields using standard period or dot (**`.`**) syntax instead of the colon (**`:`**) syntax we use for the JSON string<br/>

    :::info
        ```sql
        SELECT
            customer_id,
            profile_struct.first_name,
            profile_struct.address.country
        FROM parsed_customers
        ```
    :::

## How to flatten fields into columns from a nested data structure with **`*`** operation

- [ ] Once a JSON string is converted to a **`struct`** type, we can use the **`*`** operation to flatten fields into columns

    :::info
        ```sql {4}
        CREATE OR REPLACE TEMP VIEW customers_final AS 
        SELECT 
            customer_id, 
            profile_struct.*
        FROM parsed_customers;
        
        SELECT * FROM customers_final
        ```
    :::

- [ ] As you can see here, the **`first_name`**, **`last_name`**, **`gender`** and the **`address`** itself are all now separate columns

## How to put each element of an array on its own row with **`explode`** function

- [ ] Let us now switch to our **`orders`** tables to see another interesting feature, which is the **`explode`** function<br/>

- [ ] Let us first explore again some fields of our table

    :::info
        ```sql {4}
        SELECT 
            orders_id, 
            customers_id,
            books
        FROM orders
        ```
    :::

- [ ] Here, the **`books`** column is an array of **`struct`** type<br/>

- [ ] Spark SQL has a number of functions specifically to deal with arrays<br/>

- [ ] The most important one is the **`explode`** function that allows us to put each element of an array on its own row<br/>

- [ ] Each element of the book's array has its own row and we are repeating the other information like the **`customer_id`** and the **`order_id`**

    :::info
        ```sql
        SELECT 
            order_id, 
            customer_id,
            explode(books) AS book
        FROM orders
        ```
    :::

## How to collect unique values from a field (including fields within an array) with **`collect_set`** function

- [ ] Another interesting function is the **`collect_set`** aggregation function that allows us to collect unique values for a field, including fields within arrays<br/>

    :::info
        ```sql {3-4}
        SELECT
            customer_id,
            collect_set(order_id) AS orders_set,
            collect_set(books.book_id) AS book_set
        FROM orders
        GROUP BY customer_id
        ```
    :::

- [ ] As you can see here, the **`books_set`** column is actually an array of array<br/>

- [ ] The question, can we flatten this array? Yes, we can

## How to keep only the distinct values from an array

- [ ] In addition, we can also keep only the distinct values as, for example, for the **`B08`** that is exist in 2 elements of the array

    :::info
        Instead of having the **`B08`** twice after flatten the array, we will get only one unique value
    :::

- [ ] Here we are applying **`flatten`** function and then we apply the **`array_distinct`** function to keep only the distinct values. And here we can see the final results before and after

    :::info
        ```sql {3-7}
        SELECT
            collect_set(books.book_id) AS before_flatten,
            array_distinct(
                flatten(
                    collect_set(books.book_id)
                )
            )
        FROM orders
        GROUP BY customer_id
        ```
    :::

- [ ] Here we can see the final results before and after

## JOIN operations in Spark SQL

- [ ] Let us now switch to join operations<br/>

- [ ] Spark SQL supports standard join operations:
    
    - **`INNER`**; 
    - **`OUTER`**; 
    - **`LEFT`**; 
    - **`RIGHT`** 
    - **`Cross joins`**<br/>

- [ ] Here we  are joining the result of the **`explode`** operation to the books lookup table in order to retrieve books information like **`books`**, **`title`**, and author's **`name`**.<br/>

- [ ] We simply specify the type of the operation to apply. In our case, it's an inner join based on the **`book_id`** key<br/>

- [ ] We are storing the results in a view called **`orders_enriched`**

    :::info
        ```sql {9-10}
        CREATE OR REPLACE VIEW orders_enriched AS
        SELECT *
        FROM (
            SELECT 
                *,
                explode(books) AS book
            FROM orders
        ) o
        INNER JOIN books b
        ON o.book.book_id = b.book_id;
        
        SELECT * FROM orders_enriched
        ```
    :::

- [ ] As you can see, we are grabbing for each book the **`title`** and the author **`name`** and the **`category`** for this book

## How to use set operations in Spark SQL

### How to use **`UNION`** in Spark SQL

- [ ] Spark SQL also supports set operations like **`UNION`**

    :::info
        For example, we can **`UNION`** the old and the new data of the orders table

        ```sql
        CREATE OR REPLACE TEMP VIEW orders_updates 
        AS SELECT 
            *
        FROM parquet.`${dataset.bookstore}/orders-new`;
        
        SELECT
            *
        FROM orders
        UNION
        SELECT 
            *
        FROM orders_updates
        ```
    :::

### How to use **`INTERSECT`** in Spark SQL

- [ ] In the same way we can do **`INTERSECT`** operation

    :::info
        The **`INTERSECT`** command returns all rows found in both relations

        ```sql
        SELECT * FROM orders
        INTERSECT
        SELECT * FROM orders_updates
        ```
    :::

### How to use **`MINUS`** in Spark SQL

- [ ] If you are **`orders MINUS orders_updates`**, you will get only the orders data without the 700 new records<br/>

    :::info
        ```sql
        SELECT * FROM orders
        MINUS
        SELECT * FROM orders_updates
        ```
    :::

### How to use **`PIVOT`** in Spark SQL

- [ ] Spark SQL also support **`PIVOT`** clause, which is used to change data perspective<br/>

- [ ] We can get the aggregated values based on a specific column values, which will be turned to multiple columns used in **`SELECT`** clause

    :::info
        We here we have **`SELECT * FROM`** and we specify between two parentheses the **`SELECT`** statement that we will be the input for this table
    :::

- [ ] In the **`PIVOT`** clause, the first argument is an aggregation function (**`SUM`**, **`AVG`**, **`MAX`**, etc.), and the column to be aggregated. 

    :::info
        ```sql {9}
        CREATE OR REPLACE TABLE transactions AS
        SELECT * FROM (
            SELECT
                customer_id, 
                book.book_id AS book_id,
                book.quantity AS quantity
            FROM orders_enriched
        ) PIVOT (
            SUM(quantity) 
            FOR book_id IN (
                'B01',
                'B02', 
                'B03',
                'B04',
                'B05',
                'B06',
                'B07',
                'B08',
                'B09',
                'B10',
                'B11',
                'B12',     
            )
        );
        
        SELECT * FROM transactions
        ```
    :::


- [ ] Then we specify the **`PIVOT`** column in the **`FOR`** subclause. The **`IN`** operator contains the pivot column values

    :::info
        ```sql {10-22}
        CREATE OR REPLACE TABLE transactions AS
        SELECT * FROM (
            SELECT
                customer_id, 
                book.book_id AS book_id,
                book.quantity AS quantity
            FROM orders_enriched
        ) PIVOT (
            SUM(quantity) 
            FOR book_id IN (
                'B01',
                'B02', 
                'B03',
                'B04',
                'B05',
                'B06',
                'B07',
                'B08',
                'B09',
                'B10',
                'B11',
                'B12',     
            )
        );
        
        SELECT * FROM transactions
        ```
    :::

- [ ] Here we use the **`PIVOT`** command to create a new transaction table that flatten out the information contained in the orders table for each customer

    :::info
        Such a flatten data format can be useful for dashboarding, but also useful for applying machine learning algorithms for inference and predictions
    :::