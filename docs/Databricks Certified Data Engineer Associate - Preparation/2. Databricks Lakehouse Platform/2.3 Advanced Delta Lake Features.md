# 2.3 Advanced Delta Lake Features

- [ ] In this video, we will talk about the advanced features of the Delta Lake

## Time travel feature in Delta Lake

- [ ] With Delta, every operation on the table is automatically versioned, which provides the full audit trail of all the changes that have happened on the table<br/>

- [ ] You can look at the history of the table in SQL using **`DESCRIBE HISTORY`** command<br/>

- [ ] In addition, we can query older versions of the table. This can be done in two different ways

1. **Use a timestamp**, So, in a **`SELECT`** statement we use the keyword **`TIMESTAMP AS OF`** and we provide the time or date string

    :::info
        ```sql {2}
        SELECT * FROM my_table 
        TIMESTAMP AS OF "2019-01-01"
        ```
    :::

2. **Use a version number**

    * Since every operation on the table has a version number, you can use this version number to travel back in time as well.

    * Here using the keyword **`VERSION AS OF`**, or simply **`@v`**, which is the short syntax

    :::info
        ```sql
        SELECT * FROM my_table VERSION AS OF 36
        
        SELECT * FROM my_table @v36
        ```
    :::

- [ ] Time travel also makes it easy to do rollbacks in case of bad writes

    :::info
        For example, if your pipeline job had a bug that accidentally deleted user information, you can easily fix this using the RESTORE TABLE command. Either to restore the table to a specific timestamp or to a specific version number

        ```sql
        RESTORE TABLE my_table TO TIMESTAMP AS OF "2019-01-01"
        
        RESTORE TABLE my_table TO VERSION AS OF 36
        ```
    :::

## Compacting small files feature in Delta Lake

- [ ] Delta Lake can improve the speed of read queries from a table<br/>

- [ ] One way to improve this speed is by compacting small files into larger ones<br/>

- [ ] You trigger compaction simply by running the **`OPTIMIZE`** command

    :::info
        ```sql
        OPTIMIZE my_table
        ```

        For example, if you have many files by running the **`OPTIMIZE`** command, they will be compacted in one or more larger files which improves the table performance
    :::

## Z-order indexing in Delta Lake

- [ ] With **`OPTIMIZE`**, we can also do z-order indexing. Z-order indexing in Delta Lake is about co-locating and reorganizing column information in the same set of files<br/>

- [ ] This can be done by adding the **`ZORDER BY`** keyword to the **`OPTIMIZE`** command, followed by one or more column name

    :::info
        ```sql
        OPTIMIZE my_table ZORDER BY colum_name
        ```

        For example, if you have a numerical column in the data files, ID for example, by applying the **`ZORDER`** on this column, the first compacted file will contain values from 1 to 50, while the other one will contain values from 51 to 100
    :::

- [ ] Z-Order indexing is used by data skipping algorithm to extremely reduce the amount of data that need to be read

    :::info
        In our example, if you query an ID, say 30, Delta is sure now that ID 30 is in file number 1, so it can easily skip the scanning the file number 2, which will sav a huge amount of time
    :::

## Vacuum a Delta Table

- [ ] You might be wondering what about unused data files like uncommitted files and files that are no longer in the latest state of the transaction log for the table?<br/>

- [ ] Delta Lake allows you to do garbage collection by using **`VACUUM`** command<br/>

- [ ] With **`VACUUM`** command, you just need to specify the threshold of retention period for the files, so you delete all the files older than this threshold

    :::info
        ```sql
        VACUUM table_name [retention period]
        ```

        By default, the threshold is 7 days. This means that **`VACUUM`** operation will prevent you from deleting files less than 7 days old. Just to be sure that no longer running operations are still referencing any of the files to be deleted
    :::

    :::note
        Once you run a **`VACUUM`** on a Delta table, you lose the ability to time travel back to a version older than the specified retention period, simply because the data files are no longer exist
    :::