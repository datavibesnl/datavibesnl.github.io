# 2.7 Set Up Delta Tables

- [ ] In this video, we will talk more about the Delta Lake tables<br/>

- [ ] You will understand how to use **`CTAS`** statements to create Delta tables<br/>

- [ ] We will learn how to add table constraints to an existing table<br/>

- [ ] We will see how to make a copy of a Delta table<br/>

- [ ] In addition to regular **`CREATE TABLE`** statements, we can use CTAS statements to create Delta tables<br/>

- [ ] CTAS statements or **`CREATE TABLE AS SELECT`** statements, create and populate data tables using the output of a **`SELECT`** statement<br/>

- [ ] Here is an example, we are creating **`table_1`** and fill this table by data retrieved from **`table_2`**

    :::info
        ```sql
        CREATE TABLE table_1 
        AS SELECT * FROM table_2
        ```
    :::

- [ ] CTAS statements automatically infer schema information from query results, and do not support manual schema declaration<br/>

- [ ] With CTAS statements, we can do simple transformations like changing column names or omitting columns from target tables during table creation<br/>

- [ ] In this example, the statement creates a new table, **`table_1`** containing a subset of columns from **`table_2`**

    :::info
        ```sql
        CREATE TABLE table_1 
        AS SELECT 
        col_1, 
        col_3 as new_col_3 
        FROM table_2
        ```
    :::

- [ ] In addition, the CREATE TABLE clause contains several options<br/>

- [ ] You can provide a descriptive comments fort he table. This allows for easier discovery of table contents<br/>

- [ ] Here we are adding a comment indicating that the table contains personal identifiable information like the **`name`** and the **`email`** of the user<br/>

- [ ] The underlying data of a table can be partitioned in subfolders by the value of one or more columns<br/>

- [ ] Here we are partitioning by the **`city`** and **`birthdate`**

    :::info
        ```sql
        CREATE TABLE new_table
        COMMENT "Contains PII"
        PARTITIONED BY (city, birth_date)
        LOCATION '/some/path'
        AS SELECT 
        id, 
        name,
        email,
        birth_date,
        city
        FROM users
        ```
    :::

- [ ] Partitioning can improve the performance of a huge delta tables. On the other hand, small to medium sized tables will not benefit from partitioning, because partitioning physically separates data files which results in a small files problem<br/>

    :::info
        This can prevent file compaction and efficient data skipping
    :::

- [ ] As a best practice, you should default to non-partitioned tables for most use cases when working with delta tables<br/>

- [ ] The created table with CTAS statements can be an external table, so the data will be stored in an external location specified by the **`LOCATION`** keyword<br/>

- [ ] Let us see this comparison between regular **`CREATE TABLE`** statements and CTAS statements<br/>

- [ ] Regular **`CREATE TABLE`** statements need manual schema declaration

    :::info
        For example, Column 1 of type Integer. Column 2 of type String and column 3 of type Double
    :::

- [ ] While CTAS statements do not support manual schema declaration. They automatically inferior schema informations from a query results<br/>

- [ ] Regular **`CREATE TABLE`** statements create an empty table. So, you need an **`INSERT INTO`** statement to load data into the table<br/>

- [ ] With CTAS statements, data will be inserted during table creation from the output of the **`SELECT`** statement<br/>

## Table Constraints

- [ ] Once you create your Delta table, either with regular **`CREATE TABLE`** or CTAS statements, you can add constraints to your table<br/>

- [ ] Databricks currently supports two types of table constraints, **`NOT NULL`** constraints and **`CHECK`** constraints<br/>

- [ ] In both cases, you must ensure that there is no data violating the constraint is already in the table prior to defining the constraint<br/>

- [ ] Once a constraint has been added to a table, new data violating the constraint would result in write failure<br/>

- [ ] In this example, we add a Check constraint to the date column of our table.

    :::info
        Note that check constraints look like standard WHERE clauses you might use to filter a dataset

        ```sql
        ALTER TABLE orders
        ADD CONSTRAINT valid_date
         CHECK (date > '2020-01-01')
        ```
    :::

## Cloning Delta Lake Tables

- [ ] What if you want to backup or make a copy of your delta table?<br/>

- [ ] For this Delta Lake has two options for efficiently copying Delta Tables

1. **`DEEP CLONE`**

    :::info
        Deep clone fully copies both data and metadata from a source table to a target<br/>

        The command is pretty simple. **`CREATE TABLE`** and you provide the name of the new target table, followed by **`DEEP CLONE`** keyboard and you indicate the name of the source table

        ```sql
        CREATE TABLE table_clone
        DEEP CLONE source_table
        ```
        This copy can occur incrementally<br/>

        Executing this command again can synchronize changes from the source to the target location. And because all the data must be copied over, this can take a while for large data sets
    :::

2. **`SHALLOW CLONE`**

    :::info
        With **`SHALLOW CLONE`**, you can quickly create a copy of a table since it just copies the Delta transaction logs<br/>

        That means there is no data moving during shallow cloning

        ```sql
        CREATE TABLE table_clone
        SHALLOW CLONE source_table
        ```

        **`SHALLOW CLONE`** is a good option, for example, to test out applying changes on a table without the risk of modifying the current table
    :::

- [ ] In either cases, deep or shallow, data modification applied to the cloned version of the table will be tracked and stored separately from the source, so it will not affect the source table