# 2.6 Databases and Tables on Databricks (Hands On)

- [ ] In this notebook, we will work with databases and tables on Databricks<br/>

- [ ] Let us first take a look on the **`Data Explorer`**. Here we can see the Hive metastore for this Databricks workspace

    :::info
        By default, it has a database called default
    :::

- [ ] Let us create some tables in this default database<br/>

- [ ] Let us create a tabled called **`managed_default`** and insert some data

    :::info "Example: Create a managed table"
        ```sql
        CREATE TABLE managed_default (
            width INT,
            length INT,
            height INT
        );
        
        INSERT INTO managed_default
        VALUES (
            3 INT, 2 INT, 1 INT
        )
        ```
    :::

    :::note
        It is a managed table since we are not specifying **`LOCATION`** keywords
    :::

- [ ] If we come back to the **`Data Explorer`**, we see that the table **`managed_default`** has been created under the default database<br/>

- [ ] Let us run the **`DESCRIBE EXTENDED`** command on our table to see some metadata information

    :::info
        ```sql
        DESCRIBE EXTENDED managed_default
        ```
    :::

- [ ] Here we see that there are 17 rows of metadata. Let us scroll to see two useful information about our table

    1. The location. Here, we can see that our table is created under the default Hive metastore, which is **`dbfs:/user/hive/warehouse`**

    2. The type of the table is **`MANAGED`**

    :::info
        It's a managed table since we didn't specify **`LOCATION`** keyword during the creation of the table
    :::

## How to create an external table

- [ ] Let us now create an external table under the default database<br/>

- [ ] To create an external table, you need to simply to specify in the **`CREATE TABLE`** statement the **`LOCATION`** keyword followed by the path to where this table needs to be stored.

    :::info
        In our case, we store this table under **`/mnt/demo`** directory

        ```sql
        CREATE TABLE managed_default (
            width INT,
            length INT,
            height INT
        ) LOCATION 'dbfs:/mnt/demo/external_default';
        
        INSERT INTO managed_default
        VALUES (
            3 INT, 2 INT, 1 INT
        )
        ```
    :::

- [ ] Let us take a look on the **`Data Explorer`**. Here we can see that the table has been created in the hive metastore<br/>

- [ ] Let us now run **`DESCRIBE EXTENDED`** on our external table

    :::info
        ```sql
        DESCRIBE EXTENDED external_default
        ```
    :::

- [ ] Here we can see that this table is indeed an external table, and it is created in the specified location under /mnt/demo. Let us now see what will happen if we drop the managed table<br/>

- [ ] The table has been successfully deleted. Let us confirm this by checking the table directory

    :::info
        ```sh
        %fs ls 'dbfs:/user/hive/warehouse/managed_default'
        ```

        ```sql
        DROP TABLE external_default
        ```
    :::

- [ ] In the hive metastore, we see that both tables are no longer exist<br/>

    :::info
        However, if we check the table directory. We see that the table directory and the data files are still there

        ```sh
        %fs ls 'dbfs:/mnt/demo/external_default'
        ```
    :::

- [ ] Since this table is created outside the database directory, the underlying data is not managed by Hive. So, dropping the table will not delete the underlying data files as we see here<br/>

- [ ] In addition to the default database, we can also create extra databases. To do so we can use either **`CREATE SCHEMA`** syntax or **`CREATE DATABASE`** syntax, which is actually the same

    :::info
        ```sql
        CREATE SCHEMA new_default
        ```
    :::

- [ ] Here we can see that the new database has been created<br/>

- [ ] Let us run the **`DESCRIBE DATABASE EXTENDED`** on our database to see some metadata information

    :::info
        ```sql
        DESCRIBE DATABASE EXTENDED new_default
        ```
    :::

- [ ] Here we can see that the database itself is created under the default Hive warehouse directory<br/>

    :::info
        *Notice that the database has .db extension to differentiate it from other table folders in the same directory*
    :::

- [ ] Let us create some tables in this new database<br/>

- [ ] Here we will create also a managed table and an external table

    :::info
        ```sql
        USE new_default;
        
        /* managed table */
        CREATE TABLE managed_new_default (
            width INT,
            length INT,
            height INT
        );
        
        INSERT INTO managed_new_default VALUES (
            3 INT, 2 INT, 1 INT
        );
        
        /* external table */
        CREATE TABLE external_new_default (
            width INT,
            length INT,
            height INT
        ) LOCATION 'dbfs:/mnt/demo/external_new_default';
        
        INSERT INTO external_new_default VALUES (
            3 INT, 2 INT, 1 INT
        );
        ```
    :::

- [ ] To create a new table in a database different then the default one, you need to specify the database tob e used through the USE keywords<br/>

- [ ] Let us run this command. In the **`Data Explorer`**, we see that the two tables have been created

    :::info
        ```sql
        DESCRIBE EXTENDED managed_new_default
        ```
    :::

- [ ] Here, we can see that this new table is indeed a managed table created in its database folder under the default hive warehouse directory<br/>

- [ ] The second table where we use the **`LOCATION`** keyword has been defined as external table under **`/mnt/demo`** location<br/>

- [ ] We can simply drop those two tables to see again that the table directory and the data files of the managed table have been all removed

    :::info
        ```sql
        DROP TABLE managed_new_default;
        DROP TABLE external_new_default;
        ```
    :::

- [ ] In the **`Data Explorer`**, we see that both tables have been dropped from the new database. However, as expected, the table directory and the data files of the external table are still there<br/>

- [ ] Let us finally create a database in a custom location outside of the Hive directory

    :::info
        ```sql
        CREATE SCHEMA custom
        LOCATION 'dbfs:/Shared/schemas/custom.db'
        ```
    :::

- [ ] As we can see in the **`Data Explorer`**, the database has been really created in the hive metastore. However, if we run the **`DESCRIBE DATABASE EXTENDED`**, we see that it is created in the custom location we have defined during the creation of the database, and it is different from the default hive directory

    :::info
        ```sql
        DESCRIBE DATABASE EXTENDED custom
        ```
    :::

- [ ] You can normally create managed and external tables in this database

    :::info
        ```sql
        USE custom;
        
        /* managed table */
        CREATE TABLE managed_custom (
            width INT,
            length INT,
            height INT
        );
        
        INSERT INTO managed_custom VALUES (
            3 INT, 2 INT, 1 INT
        );
        
        /* external table */
        CREATE TABLE external_custom (
            width INT,
            length INT,
            height INT
        ) LOCATION 'dbfs:/mnt/demo/external_custom';
        
        INSERT INTO external_custom VALUES (
            3 INT, 2 INT, 1 INT
        ); 
        
        ```
    :::
    
- [ ] In hive metastore, we can see the tables of our custom location<br/>

- [ ] The managed_custom table is indeed a managed table since it is created in the database folder located in a custom location<br/>

- [ ] The second table is an external table since it is created outside the database directory<br/>

- [ ] By dropping the two tables, we can see that they have successfully deleted from the hive metastore<br/>

- [ ] The managed table directory and the data files are no longer exist in the database directory located in the custom location. While the external table's directory, and its data file are not deleted and are still in this external location outside the database directory