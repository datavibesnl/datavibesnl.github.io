# 1.2 What is Databricks?

## What is Databricks?

- [ ] Databricks is a multi-cloud lakehouse platform based on Apache Spark

## What is a lakehouse?
    
- [ ]A lake house is a unified analytics platform that combines the best elements of data lakes and data warehouses.
    
    * Deliver the **openness**, **flexibility** and **machine learning support** of data lakes<br/>
    * With the **reliability**, **strong governance** and **performance** of data warehouses

- [ ] In a lakehouse architecture, you work on engineering, analytics and AI all in one platform.

## Architecture of Databricks Lakehouse

- [ ] The Databricks Lakehouse architecture is divided into 3 layers:

1. The cloud service<br/>
2. The runtime<br/>
3. The workspace

### Cloud service

- [ ] Databricks is available on the following cloud providers:<br/>

    * Microsoft Azure
    * Amazon Web Services
    * Google Cloud

### Runtime

- [ ] The Databricks runtime is a set of core components like:<br/>

    * Apache Spark
    * Delta Lake 
    * Other system libraries

- [ ] The infrastructure of the cloud provider is used to provision virtual machines or nodes of a cluster which are pre-installed with the Databricks runtime

### Workspace

- [ ] The Databricks workspace is on top of the cloud service and runtime.<br/>

- [ ] The workspace allows you to interactively implement and run your <b>data engineering</b>, <b>analytics</b> and <b>AI workloads</b>.

## How Databricks resources are deployed within your cloud provider

- [ ] Databricks consists of 2 high-level components:<br/>

1. Control plane<br/>
2. Data plane

### Control plane

- [ ] Control plane components are deployed when you create a Databricks workspace.<br/>

<p>The control plane components are services in Databricks such as:</p>

- The Databricks UI<br/>
- The Cluster Manager<br/>
- The Workflow Service<br/>
- The Notebooks

### Data plane

- [ ] If you choose Azure as a cloud provider, a storage account will be deployed in your Azure subscription as part of the Data plane.<br/>

- [ ] The storage account will be used as the Databricks File System or DBFS<br/>

- [ ] When you set up a Spark cluster, additional virtual machines will be deployed as part of the Data plane

    :::tip
        The compute and storage components will be in your own cloud account.<br/>
        Databricks will provide you with the tools you need to use and control your infrastructure from the Databricks UI
    :::

## Supported features of Databricks

- [ ] Data is **distributed** and **processed in-memory** by multiple nodes in a cluster, because Databricks is based on Apache Spark.<br/>

- [ ] Databricks supports all the languages that are supported by Spark, which are:<br/>

    * Scala<br/>
    * Python<br/>
    * SQL<br/>
    * R<br/>
    * Java

Databricks also suppports  **batch- and stream processing** in Spark<br/>

Databricks processes all types of data:<br/>
    * Structured
    * Semi-structured
    * Unstructured

## Databricks File System (DBFS)

- [ ] Databricks offers **native-support of a distributed file system** called Databricks File System (DBFS)

    :::info
        File systems are used to persist data and files
    :::

- [ ] DBFS comes pre-installed on a cluster in Databricks

    :::note
        DBFS is an abstraction layer that uses the underlying cloud storage to persist data.
    :::

    :::info
        If you create a file in your cluster and store it in DBFS. This file is persisted in the underlying cloud storage.<br/> 
        
        * Azure storage account<br/>
        * Amazon S3 buckets<br/>

        Even after the cluster is terminated, all the data is saved in your cloud storage
    :::

    

