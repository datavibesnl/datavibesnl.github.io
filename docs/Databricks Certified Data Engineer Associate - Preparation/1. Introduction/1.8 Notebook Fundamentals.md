# 1.8 Notebook Fundamentals

- [ ] In this lesson, we will practice working with Databricks Notebooks <br/>

- [ ] Click on the **`Workspace`** tab <br/>

- [ ] Choose **`Create`** and then **`Notebook`** <br/>

- [ ] Give your notebook a friendly name

    :::info
        For example, Demo notebook
    :::

- [ ] Select the default language

    :::info
        Databricks notebooks support Python, SQL, Scala and R
    :::

    :::note
        A language is selected when a notebook is created but this can be changed at any time
    :::

- [ ] Select **`Python`** <br/>

- [ ] We will choose our cluster we created in the last session <br/>

- [ ] Click **`Create`**

    :::info
        Notebooks are coding environments allowing you to interactively developing and executing code on Databricks<br/>

        You can also collaborate between different team members by sharing the notebook<br/>

        If you have previously used Jupyter Notebook, for example, you will notice that the basic functionality is the same, but with additional features and capabilities that you might enjoy
    :::

- [ ] Any time you can change the name of the notebook, simply click on the notebook name to change it

    :::info
        For example, let us change it to Notebook Basics
    :::

- [ ] Before running any computation, we need to attach our notebook to a cluster on which our code will be running <br/>

- [ ] From the top bar here, I can see all my created clusters and their status if they are running or not <br/>

- [ ] Let us connect to the **`Demo cluster`** <br/>

- [ ] Select the cluster and click **`Start`** <br/>

- [ ] Click **`Confirm`**

    :::note
        The green circle next to the cluster name indicates that the cluster is up and running
    :::

- [ ] Notebooks provide cell by cell execution of codes. <br/>

- [ ] Let us print a hello world message <br/>

- [ ] In order to run a cell, you can click on the play button and choose **`Run cell`**<br/>

- [ ] You can also run all the above cells or all the below cells

    :::info
        You can use **`Shift + Enter`** shortcut
    :::

- [ ] If needed, you can easily check the default language for a Notebook. <br/>

- [ ] Click on the **`Python`** option and select the new language from this dropdown list <br/>

- [ ] To create a new cell hover below the current cell and click the **`(+)`** button <br/>

- [ ] If you try to run some SQL code in this Python notebook, this will not work. For example, here is a **```sql SELECT```** statement. If you run this cell. You get a syntax error <br/>

- [ ] In a notebook, you can change the language of a specific cell. Simply, you need to click on the Python option and choose SQL

    :::note
        This added what we call a magic command identified by a single **`%`** sign at the start of a cell
    :::

    :::info
        Magic commands are built in commands that provide the same output regardless of the notebook language<br/>
        
        This is called Language Magic command that allows the execution of code in a language other than the notebook's default
    :::

- [ ] Another useful magic command is the markdown magic command (**`%md`**) that allows us to have a cell formatted with text <br/>

- [ ] Double click the cell to edit it and let us add more formatted text <br/>

- [ ] Once done, hit **`ESC`** to stop editing and see the results <br/>

- [ ] By adding titles using markdowns, they will be added automatically to the notebook table of content

    :::info
        On the left, click on this arrow. This is extremely useful as it allows to easily navigate your notebook
    :::

- [ ] We also have the run magic command that allows us to run another notebook from the current notebook <br/>

- [ ] To illustrate this, let us first create another notebook. From the **`Workspace`** tab, let us, for example, create a folder and name it **`Includes`** <br/>

- [ ] Within this folder, let us create a notebook and we name it **`Setup`**. Hit **`Create`** <br/>

- [ ] In this notebook, we will simply define a variable called **`full_name`** and assigned my name as a value for this variable <br/>

- [ ] Come back to our main notebook

    :::info
        ```sh
        %run ./Includes/Setup
        ```
    :::

- [ ] Let us run this cell

    :::info
        The referenced notebook here executes as if it were part of the current notebook
    :::

- [ ] If you think about this magic command, it is very powerful because it helps you to reuse your code and build your notebooks in a modular approach <br/>

- [ ] Databricks also provides the **`%fs`** magic command to deal with file system operations like **`ls`** for listing files in a given directory

    :::info
        For example, we are listing all files and folders in the default dataset location, which is available in every workspace

        ```sh
        %fs ls "/databricks-datasets"
        ```
    :::

    :::note
        This location has sample data set provided by Databricks
    :::

## Access the filesystem with **`dbutils`**

- [ ] Another way to deal with filesystem operations to use Databricks utilities, also known as **`dbutils`**

    :::info
        **`dbutils`** provides a number of utility commands for configuring and interacting with the environment
    :::

    :::note
        To get some help for each utility, you can use **`dbutils.help()`** function
    :::

- [ ] As you can see with the **`dbutils`**, you can interact with different services and tools like: credentials, fs for file system, secrets and widgets

    :::info
        **`dbutils.fs`** allows you to interact with the Databricks file system or DBFS
    :::

- [ ] To get some help on this.

    :::info
        ```sh
        dbutils.fs.help()
        ```
    :::

- [ ] From here we can see that the **`fs`** has a number of available commands, like copying and removing files <br/>

- [ ] In addition, we also have the **`ls`** command that allows us to list the content of a directory. Let us try this

    :::note
        Databricks also supports auto-completion using the **`Tab`** key
    :::

- [ ] Let us hit **`Tab`** in this case and select **`ls`**, click enter. And specify the folder path, in our case **`/databricks-datasets`**

    :::info
        ```sh
        dbutils.fs.ls('/databricks-datasets')
        ```
    :::

- [ ] The question for the file system operation, should we use **`dbutils`** or the **`%fs`** magic command we saw previously? In fact, **`dbutils`** is more useful than the **`%fs`** magic command since you can use **`dbutils`** as part of python code

    :::info
        You can get the list of files for example in a variable and do some logic with it in Python.
    :::

    :::info "Example: List files in directory"
        ```python 
        files = dbutils.fs.ls('/databricks-datasets')
        ```
    :::

- [ ] As you can see, the output is very messy and hard to read. Instead, you can display it in a much better way using the **`display`** function

    :::info
        ```python
        files = dbutils.fs.ls('/databricks-datasets')
        display(files)
        ```
    :::

- [ ] Here we see the output is rendered in a tabular format with some fields like:

    - **`path`**;
    - **`filename`**;
    - **`size`**;
    - **`modification time`**

- [ ] With the **`display`** function, you can also download data as CSV file and render the result as a graph 

    :::info
        However, the **`display`** function is **limited** to preview only 1000 records
    :::

    :::note
        When running SQL queries from cells, results will be always displayed in a tabular format like here, so there is no need to use the **`display`** function with SQL.
    :::

- [ ] At the end of the day, you may want to download your notebook. You can just click on the file menu, then **`Export`** and you choose **`IPython Notebook`** <br/>

- [ ] We can also export a folder that contains multiple notebooks from the **`Workspace`** tab. If we click next to the folder, we have the option to export it as **`DBC archive`** <br/>

    :::note
        The **DBC** or the **Databricks Cloud** file is a zip file that contains a collection of directories and notebooks<br/>

        This file can be uploaded into any Databricks workspace to move or share notebooks
    :::

- [ ] To import a notebook or a collection of notebooks in DBC file, simply click here on the down arrow and choose **`Import`** <br/>

- [ ] In Databricks, you can access the revision history of all the changes being made on a notebook <br/>

- [ ] Click on the **`Last Edit`** link. From here, you can choose any of the auto-saved versions <br/>

- [ ] Click **`Restore this revision`** <br/>